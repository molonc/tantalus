# -*- coding: utf-8 -*-
# Generated by Django 1.11.14 on 2019-01-03 00:08

import hashlib
import collections
from django.db import migrations
from django.db.models import Max


WGS_BAM_NAME_TEMPLATE = "-".join([
    "{dataset_type}",
    "{sample_id}",
    "{library_type}",
    "{library_id}",
    "lanes_{lanes_hash}",
    "{aligner}",
    "{reference_genome}",
])

WGS_FQ_NAME_TEMPLATE = "-".join([
    "{dataset_type}",
    "{sample_id}",
    "{library_type}",
    "{library_id}",
    "{lane}",
])

def get_lane_str(lane):
    if lane["lane_number"] == "":
        return "{}".format(lane["flowcell_id"])

    # Include lane number
    return "{}_{}".format(lane["flowcell_id"], lane["lane_number"])


def get_lanes_hash(lanes):
    if not lanes:
        raise ValueError("bam with no lanes")

    # More than two lanes
    lanes = ", ".join(sorted([get_lane_str(a) for a in lanes]))
    lanes = hashlib.md5(lanes)
    return "{}".format(lanes.hexdigest()[:8])


def get_created_time(dataset):
    return dataset.file_resources.all().aggregate(Max('created'))['created__max']


def get_storage_names(FileInstance, dataset):
    return list(
        FileInstance.objects.filter(
            file_resource__sequencedataset=dataset)
        .values_list('storage__name', flat=True)
        .distinct())


def rename_datasets(apps, schema_editor):
    SequenceDataset = apps.get_model('tantalus', 'SequenceDataset')
    ReferenceGenome = apps.get_model('tantalus', 'ReferenceGenome')
    FileInstance = apps.get_model('tantalus', 'FileInstance')

    datasets = dict()

    for dataset in list(SequenceDataset.objects.filter(library__library_type__name='WGS').all()):
        if get_storage_names(FileInstance, dataset) == [u'gsc']:
            for f in dataset.file_resources.all():
                f.delete()
            dataset.delete()

    datasets = collections.defaultdict(set)
    for dataset in list(SequenceDataset.objects.filter(library__library_type__name='WGS').all()):
        lane_infos = []
        for lane in dataset.sequence_lanes.all():
            lane_infos.append({'flowcell_id': lane.flowcell_id, 'lane_number': lane.lane_number})
        if dataset.dataset_type == 'BAM':
            aligner_name = 'UNALIGNED'
            if dataset.aligner is not None:
                aligner_name = dataset.aligner.name
            reference_genome_name = 'UNALIGNED'
            if dataset.reference_genome is not None:
                reference_genome_name = dataset.reference_genome.name
            new_name = WGS_BAM_NAME_TEMPLATE.format(
                dataset_type=dataset.dataset_type,
                sample_id=dataset.sample.sample_id,
                library_type=dataset.library.library_type.name,
                library_id=dataset.library.library_id,
                lanes_hash=get_lanes_hash(lane_infos),
                aligner=aligner_name,
                reference_genome=reference_genome_name,
            )
            if dataset.id == 6094:
                new_name = new_name + '_TEST'
        elif dataset.dataset_type == 'FQ':
            new_name = WGS_FQ_NAME_TEMPLATE.format(
                dataset_type=dataset.dataset_type,
                sample_id=dataset.sample.sample_id,
                library_type=dataset.library.library_type.name,
                library_id=dataset.library.library_id,
                lane=get_lane_str(lane_infos[0]),
            )
        datasets[new_name].add(dataset)

    samples = set()
    for name in datasets:
        if len(datasets[name]) <= 1:
            continue
        for dataset in datasets[name]:
            samples.add(dataset.sample.sample_id)

    for sample_id in samples:
        print sample_id

    for name in datasets:
        if len(datasets[name]) == 1:
            dataset, = datasets[name]
            dataset.name = name
            dataset.save()

        if len(datasets[name]) >= 2:
            for idx, dataset in enumerate(datasets[name]):
                new_name = name + '-V{}'.format(idx + 1)
                dataset.name = new_name
                dataset.save()


class Migration(migrations.Migration):

    dependencies = [
        ('tantalus', '0091_auto_20181228_2027'),
    ]

    operations = [
        migrations.RunPython(rename_datasets),
    ]
