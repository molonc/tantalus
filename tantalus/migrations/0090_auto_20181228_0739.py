# -*- coding: utf-8 -*-
# Generated by Django 1.11.14 on 2018-11-01 19:25
from __future__ import unicode_literals

import hashlib
import collections
from django.db import migrations
from django.db.models import Max


SC_WGS_BAM_NAME_TEMPLATE = "-".join([
    "{dataset_type}",
    "{sample_id}",
    "{library_type}",
    "{library_id}",
    "lanes_{lanes_hash}",
    "{aligner}",
    "{reference_genome}",
])

SC_WGS_FQ_NAME_TEMPLATE = "-".join([
    "{dataset_type}",
    "{sample_id}",
    "{library_type}",
    "{library_id}",
    "{lane}",
])

def get_lane_str(lane):
    if lane["lane_number"] == "":
        return "{}".format(lane["flowcell_id"])

    # Include lane number
    return "{}_{}".format(lane["flowcell_id"], lane["lane_number"])


def get_lanes_hash(lanes):
    if not lanes:
        raise ValueError("bam with no lanes")

    # More than two lanes
    lanes = ", ".join(sorted([get_lane_str(a) for a in lanes]))
    lanes = hashlib.md5(lanes)
    return "{}".format(lanes.hexdigest()[:8])


def get_created_time(dataset):
    return dataset.file_resources.all().aggregate(Max('created'))['created__max']


def rename_datasets(apps, schema_editor):
    SequenceDataset = apps.get_model('tantalus', 'SequenceDataset')
    ReferenceGenome = apps.get_model('tantalus', 'ReferenceGenome')
    datasets = dict()

    datasets = collections.defaultdict(set)
    for dataset in list(SequenceDataset.objects.filter(library__library_type__name='SC_WGS').all()):
        lane_infos = []
        for lane in dataset.sequence_lanes.all():
            lane_infos.append({'flowcell_id': lane.flowcell_id, 'lane_number': lane.lane_number})
        if dataset.dataset_type == 'BAM':
            # Fix one dataset
            if not dataset.reference_genome and dataset.id == 6094:
                dataset.reference_genome = ReferenceGenome.objects.get(name="HG19")
            new_name = SC_WGS_BAM_NAME_TEMPLATE.format(
                dataset_type=dataset.dataset_type,
                sample_id=dataset.sample.sample_id,
                library_type=dataset.library.library_type.name,
                library_id=dataset.library.library_id,
                lanes_hash=get_lanes_hash(lane_infos),
                aligner=dataset.aligner.name,
                reference_genome=dataset.reference_genome.name,
            )
            if dataset.id == 6094:
                new_name = new_name + '_TEST'
        elif dataset.dataset_type == 'FQ':
            new_name = SC_WGS_FQ_NAME_TEMPLATE.format(
                dataset_type=dataset.dataset_type,
                sample_id=dataset.sample.sample_id,
                library_type=dataset.library.library_type.name,
                library_id=dataset.library.library_id,
                lane=get_lane_str(lane_infos[0]),
            )
        datasets[new_name].add(dataset)

    # Set file instances to is_deleted=True and delete Datasets
    for name in datasets:
        assert len(datasets[name]) <= 2
        if len(datasets[name]) == 2:
            dataset1, dataset2 = datasets[name]

            dataset1_old = False
            if 'numlanes' not in dataset1.file_resources.all()[0].filename:
                dataset1_old = True

            dataset2_old = False
            if 'numlanes' not in dataset2.file_resources.all()[0].filename:
                dataset2_old = True

            files1 = set([f.id for f in dataset1.file_resources.all()])
            files2 = set([f.id for f in dataset2.file_resources.all()])

            if dataset1_old:
                assert not dataset2_old
                assert files1 != files2

                # Delete dataset1
                for f in dataset1.file_resources.all():
                    for i in f.fileinstance_set.all():
                        i.is_deleted = True
                        i.save()
                dataset1.delete()

                # Rename dataset2
                dataset2.name = name
                dataset2.save()

            elif dataset2_old:
                assert not dataset1_old
                assert files1 != files2

                # Delete dataset2

                for f in dataset2.file_resources.all():
                    for i in f.fileinstance_set.all():
                        i.is_deleted = True
                        i.save()
                dataset2.delete()

                # Rename dataset1
                dataset1.name = name
                dataset1.save()

            else:
                assert files1 == files2

                # Delete oldest by pk
                delete_pk, keep_pk = sorted([dataset1.id, dataset2.id])
                dataset = SequenceDataset.objects.get(id=delete_pk)
                dataset.delete()

                # Rename newest
                dataset = SequenceDataset.objects.get(id=keep_pk)
                dataset.name = name
                dataset.save()


class Migration(migrations.Migration):

    dependencies = [
        ('tantalus', '0089_auto_20181228_0728'),
    ]

    operations = [
        migrations.RunPython(rename_datasets),
    ]
